{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Tensorflow project using MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
    "from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale to range 0..1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add channels\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle dataset and prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "training_dataset = training_dataset.shuffle(buffer_size=training_dataset.cardinality()).batch(32)\n",
    "\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_1conv, self).__init__()\n",
    "\n",
    "        self.conv = Conv2D(filters=n_of_filters,\n",
    "                           kernel_size=3,\n",
    "                           activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_2conv, self).__init__()\n",
    "\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[0],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[1],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create instances of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different model parameters\n",
    "filters = [4, 8, 16, 32, 64]\n",
    "dense_neurons = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Models with one Convolutional Layer\n",
    "conv1_var_f = [model_1conv(n_of_filters=f, n_of_dense_neurons=128) for f in filters]            # Variated filters\n",
    "conv1_var_d = [model_1conv(n_of_filters=32, n_of_dense_neurons=dn) for dn in dense_neurons]     # Variated number of neurons in Dense layer\n",
    "\n",
    "# Model with two Convolutional Layers\n",
    "conv2_var_f = [model_2conv(n_of_filters=(f, f), n_of_dense_neurons=128) for f in filters]               # Variated filters\n",
    "conv2_var_f = [model_2conv(n_of_filters=(32, 32), n_of_dense_neurons=dn) for dn in dense_neurons]       # Variated number of neurons in Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss functions and optimizers for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_objects = [MeanAbsoluteError, MeanSquaredError, SparseCategoricalCrossentropy]\n",
    "optimizers = [Adam, SGD, Adagrad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for measurement of model's loss and accuracy\n",
    "training_loss = Mean(name=\"train_loss\")\n",
    "testing_loss = Mean(name=\"test_loss\")\n",
    "\n",
    "training_accuracy = SparseCategoricalAccuracy(name=\"train_acc\")\n",
    "testing_accuracy = SparseCategoricalAccuracy(name=\"test_acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model's training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function as Tensorflow Graph\n",
    "@tf.function\n",
    "def train_step(model, loss_object, optimizer, images, labels):\n",
    "\n",
    "    # Automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    training_loss(loss)\n",
    "    training_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function as Tensorflow Graph\n",
    "@tf.function\n",
    "def test_step(model, loss_object, images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    loss = loss_object(labels, predictions)\n",
    "\n",
    "    testing_loss(loss)\n",
    "    testing_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and model metrics acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OF_EPOCHS = 5\n",
    "\n",
    "for epoch in N_OF_EPOCHS:\n",
    "    raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
