{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Tensorflow project using MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
    "from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale to range 0..1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add channels\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle dataset and prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "training_dataset = training_dataset.shuffle(buffer_size=training_dataset.cardinality()).batch(32)\n",
    "\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_1conv, self).__init__()\n",
    "\n",
    "        self.conv = Conv2D(filters=n_of_filters,\n",
    "                           kernel_size=3,\n",
    "                           activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_2conv, self).__init__()\n",
    "\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[0],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[1],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create instances of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different model parameters\n",
    "filters = [4, 8, 16, 32, 64]\n",
    "dense_neurons = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Models with one Convolutional Layer\n",
    "conv1_var_f = [model_1conv(n_of_filters=f, n_of_dense_neurons=128) for f in filters]            # Variated filters\n",
    "conv1_var_d = [model_1conv(n_of_filters=32, n_of_dense_neurons=dn) for dn in dense_neurons]     # Variated number of neurons in Dense layer\n",
    "\n",
    "# Model with two Convolutional Layers\n",
    "conv2_var_f = [model_2conv(n_of_filters=(f, f), n_of_dense_neurons=128) for f in filters]               # Variated filters\n",
    "conv2_var_f = [model_2conv(n_of_filters=(32, 32), n_of_dense_neurons=dn) for dn in dense_neurons]       # Variated number of neurons in Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss functions and optimizers for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_objects = [MeanAbsoluteError(), MeanSquaredError(), SparseCategoricalCrossentropy(from_logits=True)]\n",
    "optimizers = [Adam(), SGD(), Adagrad()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for measurement of model's loss and accuracy\n",
    "training_loss = Mean(name=\"train_loss\")\n",
    "testing_loss = Mean(name=\"test_loss\")\n",
    "\n",
    "training_accuracy = SparseCategoricalAccuracy(name=\"train_acc\")\n",
    "testing_accuracy = SparseCategoricalAccuracy(name=\"test_acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model's training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function as Tensorflow Graph\n",
    "# @tf.function\n",
    "def train_step(model, loss_object, optimizer, images, labels):\n",
    "\n",
    "    # Automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    training_loss(loss)\n",
    "    training_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function as Tensorflow Graph\n",
    "# @tf.function\n",
    "def test_step(model, loss_object, images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    loss = loss_object(labels, predictions)\n",
    "\n",
    "    testing_loss(loss)\n",
    "    testing_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and model metrics acquisition\n",
    "\n",
    "The deafult model has one Convolutional Layer with 32 filters and a Dense Layer with 128 neurons, uses SparseCategoricalCrossentropy to calculate loss and uses Adam optimizer.\n",
    "\n",
    "I decided to compare models after changing one of the following aspects:\n",
    "\n",
    "- Number of filters used in Convolutional Layers\n",
    "- Number of neurons used in Dense Layers\n",
    "- What impact will adding one additional Convolutional Layer have (and if previously mentions aspects matter after adding it)\n",
    "- Type of Loss Function used\n",
    "- Type of optimizer used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.19081434607505798, Accuracy: 94.49666595458984, Test Loss: 0.11904497444629669, Test Accuracy: 96.94999694824219\n",
      "Epoch 2, Loss: 0.13274702429771423, Accuracy: 97.19833374023438, Test Loss: 0.12953998148441315, Test Accuracy: 97.45999908447266\n",
      "Epoch 3, Loss: 0.1497093141078949, Accuracy: 97.66667175292969, Test Loss: 0.12162347137928009, Test Accuracy: 97.8499984741211\n",
      "Epoch 4, Loss: 0.13980062305927277, Accuracy: 98.17666625976562, Test Loss: 0.16865743696689606, Test Accuracy: 97.75999450683594\n",
      "Epoch 5, Loss: 0.12703628838062286, Accuracy: 98.44833374023438, Test Loss: 0.16577428579330444, Test Accuracy: 97.86000061035156\n"
     ]
    }
   ],
   "source": [
    "test_model = [model_1conv(32, 128)]\n",
    "\n",
    "N_OF_EPOCHS = 5\n",
    "\n",
    "# Training and testing of models with one Convolutional Layer and variated number of filters\n",
    "# for model in conv1_var_f:       # [4, 8, 16, 32, 64]\n",
    "for model in test_model:\n",
    "    for epoch in range(N_OF_EPOCHS):\n",
    "\n",
    "        # Metrics reset\n",
    "        training_loss.reset_states()\n",
    "        testing_loss.reset_states()\n",
    "        training_accuracy.reset_states()\n",
    "        testing_accuracy.reset_states()\n",
    "\n",
    "        # Training\n",
    "        for train_images, train_labels in training_dataset:\n",
    "            train_step(model=model,\n",
    "                       loss_object=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       optimizer=Adam(),\n",
    "                       images=train_images,\n",
    "                       labels=train_labels)\n",
    "        \n",
    "        # Testing\n",
    "        for test_images, test_labels in testing_dataset:\n",
    "            test_step(model=model,\n",
    "                      loss_object=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      images=test_images,\n",
    "                      labels=test_labels)\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}, \"\n",
    "              f\"Loss: {training_loss.result()}, \"\n",
    "              f\"Accuracy: {training_accuracy.result() * 100}, \"\n",
    "              f\"Test Loss: {testing_loss.result()}, \"\n",
    "              f\"Test Accuracy: {testing_accuracy.result() * 100}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
