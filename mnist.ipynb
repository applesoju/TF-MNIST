{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Tensorflow project using MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patry\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale to range 0..1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add channels\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle dataset and prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "training_dataset = training_dataset.shuffle(buffer_size=training_dataset.cardinality()).batch(32)\n",
    "\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_1conv, self).__init__()\n",
    "\n",
    "        self.conv = Conv2D(filters=n_of_filters,\n",
    "                           kernel_size=3,\n",
    "                           activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2conv(Model):\n",
    "    # Constructor\n",
    "    def __init__(self, n_of_filters, n_of_dense_neurons):\n",
    "        super(model_1conv, self).__init__()\n",
    "\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[0],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.conv_1 = Conv2D(filters=n_of_filters[1],\n",
    "                             kernel_size=3,\n",
    "                             activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(n_of_dense_neurons, activation=\"relu\")\n",
    "        self.dense_2 = Dense(10)\n",
    "\n",
    "    # Call method\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create instances of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different model parameters\n",
    "filters = [4, 8, 16, 32, 64]\n",
    "dense_neurons = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Models with one Convolutional Layer\n",
    "conv1_var_f = [model_1conv(n_of_filters=f, n_of_dense_neurons=128) for f in filters]            # Variated filters\n",
    "conv1_var_d = [model_1conv(n_of_filters=32, n_of_dense_neurons=dn) for dn in dense_neurons]     # Variated number of neurons in Dense layer\n",
    "\n",
    "# Model with two Convolutional Layers\n",
    "conv2_var_f = [model_2conv(n_of_filters=(f, f), n_of_dense_neurons=128) for f in filters]               # Variated filters\n",
    "conv2_var_f = [model_2conv(n_of_filters=(32, 32), n_of_dense_neurons=dn) for dn in dense_neurons]       # Variated number of neurons in Dense layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
